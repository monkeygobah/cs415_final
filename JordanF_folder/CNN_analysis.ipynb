{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db894d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a87030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_disease(filename):\n",
    "    \"\"\"\n",
    "    Check to see if image is TB or not.\n",
    "    Input: name of image (last str position is label)\n",
    "    Output: Boolean value of disease or not\n",
    "    \"\"\"\n",
    "    if filename[-5] == '1':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def increase_contrast(image, box_size=8, lim=2):\n",
    "    \"\"\"\n",
    "    Increase contrast of image\n",
    "    Input: Image\n",
    "    Optional: box size and clip limit- can finetune these\n",
    "    Output: contrast increased image  \n",
    "    \"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=lim, tileGridSize=(box_size, box_size))\n",
    "    return clahe.apply(image)\n",
    "\n",
    "def extraction(file, data_dict):\n",
    "    \"\"\" \n",
    "    Function to extract Harris corners, sift keypoints, and threshold images and store results in data dictionaries\n",
    "    Inputs: image, path to file to determine label\n",
    "    outputs: dictionary containing the metrics\n",
    "    \"\"\"\n",
    "    image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # increase the contrast\n",
    "    cont_image = increase_contrast(image)\n",
    "    resized_img = cv2.resize(cont_image, (995, 750))\n",
    "    channeled_img = np.stack((resized_img,) * 3, axis=-1)\n",
    "    data_dict['image'].append(channeled_img)\n",
    "    \n",
    "    # store rest of the data in the dictionary\n",
    "    if determine_disease(file):\n",
    "        data_dict['label'].append(1)\n",
    "    else:\n",
    "        data_dict['label'].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2aeb8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionaries(path):\n",
    "\n",
    "    # store all of the filenames in a list\n",
    "    filenames = [ ]\n",
    "    for root, _, files in os.walk(path): \n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                path_name = os.path.join(root, file) \n",
    "                filenames.append(path_name)\n",
    "                \n",
    "    # create random permutation of indices\n",
    "    indices = np.random.permutation(len(filenames))\n",
    "\n",
    "    # split into 80/20\n",
    "    split = int(len(filenames) * 0.8)\n",
    "    train_indices = indices[:split]\n",
    "    test_indices = indices[split:]\n",
    "\n",
    "    # split the filenames\n",
    "    train_filenames = [filenames[i] for i in train_indices]\n",
    "    test_filenames = [filenames[i] for i in test_indices]\n",
    "\n",
    "    print(\"Training set size:\", len(train_filenames))\n",
    "    print(\"Testing set size:\", len(test_filenames))\n",
    "    \n",
    "    data_train =  {'label' : [], 'image' : []}\n",
    "    data_test  =  {'label' : [], 'image' : []}\n",
    "\n",
    "    # populate train and test dictionaries separately \n",
    "    split_dicts = ['train', 'test']\n",
    "    for split_type in split_dicts:\n",
    "        # build training dictionary\n",
    "        if split_type == 'train':\n",
    "            for idx, filename in enumerate(train_filenames):\n",
    "                print(f'Train image: {idx}')\n",
    "                extraction(filename, data_train) \n",
    "                \n",
    "        # build testing dictionary\n",
    "        else:\n",
    "            for idx, filename in enumerate(test_filenames):\n",
    "                print(f'Test image: {idx}')\n",
    "                extraction(filename, data_test)\n",
    "                \n",
    "    data_train['image'] = np.array(data_train['image'])\n",
    "    data_train['label'] = np.array(data_train['label'])\n",
    "    data_test['image'] = np.array(data_test['image'])\n",
    "    data_test['label'] = np.array(data_test['label'])\n",
    "    return data_train, data_test\n",
    "\n",
    "\n",
    "''' \n",
    "pickle data dictionaries to not have to extract features multiple times\n",
    "'''\n",
    "def pickle_out(file, data):\n",
    "    # Save to a pickle file\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "        \n",
    "def pickle_in(file):\n",
    "    # Load from a pickle file\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24bd37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "SET UP EXPERIMENTAL DESIGN HERE\n",
    "Choose if you want to load data directly in from pickle file or make dicts by starting feature extraction\n",
    "\"\"\"\n",
    "make_dicts = False\n",
    "want_to_pickle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff8d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_dicts:\n",
    "    path = 'C:/Users/jjfan/OneDrive - University of Illinois Chicago/Documents/Computer Science/CS 415/Project/clean_images'\n",
    "    data_train_loaded, data_test_loaded = build_dictionaries(path)\n",
    "    if want_to_pickle:\n",
    "        pickle_out('data_train_2.pickle', data_train_loaded)\n",
    "        pickle_out('data_test_2.pickle', data_test_loaded)\n",
    "else:\n",
    "    data_train_loaded = pickle_in('data_train_2.pickle')\n",
    "    data_test_loaded = pickle_in('data_test_2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fd3d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529, 750, 995, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data_train_loaded['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e991da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.VGG16(input_shape=(750, 995, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27579edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# # Build the CNN model\n",
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1500, 1946, 1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))  # Sigmoid for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6555cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "17/17 [==============================] - 1807s 106s/step - loss: 159.4142 - accuracy: 0.6578 - val_loss: 26.1123 - val_accuracy: 0.7218\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 1638s 99s/step - loss: 11.1651 - accuracy: 0.8412 - val_loss: 10.3534 - val_accuracy: 0.8496\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 1390s 84s/step - loss: 1.7931 - accuracy: 0.9471 - val_loss: 4.0089 - val_accuracy: 0.8722\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 1528s 92s/step - loss: 0.1618 - accuracy: 0.9830 - val_loss: 3.1023 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 1450s 86s/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 3.6349 - val_accuracy: 0.8797\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 1409s 84s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 3.4957 - val_accuracy: 0.8722\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 1368s 82s/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 3.6304 - val_accuracy: 0.8797\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 1658s 100s/step - loss: 3.3010e-05 - accuracy: 1.0000 - val_loss: 4.4953 - val_accuracy: 0.8647\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 1374s 82s/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 3.8536 - val_accuracy: 0.8872\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 1506s 91s/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 3.9324 - val_accuracy: 0.8722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a7b3d79610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(data_train_loaded['image'], data_train_loaded['label'], epochs=10, batch_size=32, validation_data=(data_test_loaded['image'], data_test_loaded['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dadd7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('model_1.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ba1e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5/5 [==============================] - 257s 47s/step - loss: 3.9324 - accuracy: 0.8722\n",
      "Test accuracy: 0.8721804618835449\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(data_test_loaded['image'], data_test_loaded['label'])\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55916971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 274s 48s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87        62\n",
      "           1       0.94      0.82      0.87        71\n",
      "\n",
      "    accuracy                           0.87       133\n",
      "   macro avg       0.88      0.88      0.87       133\n",
      "weighted avg       0.88      0.87      0.87       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data_test_loaded['image'])\n",
    "\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(data_test_loaded['label'], y_pred_binary)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f94b8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_1.pickle', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f8cdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f4c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jjfan\\anaconda3\\envs\\cs415env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "17/17 [==============================] - 1889s 110s/step - loss: 143.6211 - accuracy: 0.6843 - recall: 0.6453 - val_loss: 37.1501 - val_accuracy: 0.7744 - val_recall: 0.8873\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 1569s 93s/step - loss: 23.0972 - accuracy: 0.8582 - recall: 0.8679 - val_loss: 21.2224 - val_accuracy: 0.8195 - val_recall: 0.8310\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 1424s 85s/step - loss: 5.2925 - accuracy: 0.9490 - recall: 0.9585 - val_loss: 18.9977 - val_accuracy: 0.8647 - val_recall: 0.8310\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 1593s 96s/step - loss: 0.6141 - accuracy: 0.9849 - recall: 0.9925 - val_loss: 15.7649 - val_accuracy: 0.8872 - val_recall: 0.8592\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 1533s 93s/step - loss: 0.0379 - accuracy: 0.9943 - recall: 0.9962 - val_loss: 15.3205 - val_accuracy: 0.8872 - val_recall: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eb90347650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model2.fit(data_train_loaded['image'], data_train_loaded['label'], epochs=5, batch_size=32, validation_data=(data_test_loaded['image'], data_test_loaded['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d32a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_2.pickle', 'rb') as f:\n",
    "    model2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a7998db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 281s 52s/step - loss: 17.1371 - accuracy: 0.8647 - recall: 0.8310\n",
      "Test accuracy: 0.8646616339683533\n",
      "Test recall: 0.8309859037399292\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc, test_recall = model2.evaluate(data_test_loaded['image'], data_test_loaded['label'])\n",
    "print(f'Test accuracy: {test_acc}\\nTest recall: {test_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ace3183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 279s 50s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        62\n",
      "           1       0.91      0.83      0.87        71\n",
      "\n",
      "    accuracy                           0.86       133\n",
      "   macro avg       0.87      0.87      0.86       133\n",
      "weighted avg       0.87      0.86      0.86       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(data_test_loaded['image'])\n",
    "\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(data_test_loaded['label'], y_pred_binary)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5277c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_2.pickle', 'wb') as f:\n",
    "    pickle.dump(model2, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
